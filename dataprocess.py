import json
import os
#ØªØ³Øª ÙØ§ÛŒÙ„
def read_json_file():
    try:
        desktop_path = os.path.join("D:\\", "home-page.txt")
        with open(desktop_path, "r", encoding="utf-8") as file:
            data = json.load(file)
            return data
    except FileNotFoundError:
        print("âŒ ÙØ§ÛŒÙ„ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ ÙØ§ÛŒÙ„ 'home-page.txt' Ø±ÙˆÛŒ Ø¯Ø±Ø§ÛŒÙˆ D ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯.")
    except json.JSONDecodeError:
        print("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ JSON. Ù…Ù…Ú©Ù† Ø§Ø³Øª ÙØ§ÛŒÙ„ Ø®Ø±Ø§Ø¨ ÛŒØ§ Ù†Ø§ØµØ­ÛŒØ­ Ø¨Ø§Ø´Ø¯.")
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡: {e}")
data = read_json_file()
# Ø¨Ø±Ø§ÛŒ Ú†Ø§Ù¾ Ú©Ù„ Ø¬ÛŒØ³ÙˆÙ† Ù…ÛŒØ´Ù‡ Ø§ÛŒÙ† Ø®Ø· Ù¾Ø§ÛŒÛŒÙ† Ø±Ùˆ Ù‡Ø´ØªÚ¯Ø´Ùˆ Ø¨Ø±Ø¯Ø§Ø´Øª
# print(data)

print("***ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø®ØªØ§Ø± Ú©Ù„ÛŒ ÙØ§ÛŒÙ„***")
print("---------------"*10)

#Ù…Ø´Ø®ØµØ§Øª ÙØ§ÛŒÙ„
def structure(data):
    print(":Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡ Ø§ØµÙ„ÛŒ", "\t", type(data).__name__)
    if isinstance(data, dict) or isinstance(data, list):
        print(":ØªØ¹Ø¯Ø§Ø¯ Ø¢ÛŒØªÙ… Ù‡Ø§ÛŒ Ø³Ø·Ø­ Ø§ÙˆÙ„","\t" , len(data))
    else:
        print("Ù„ÛŒØ³Øª Ùˆ ÛŒØ§ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª")
structure(data)

def max_depth(data, depth = 1):
    if isinstance(data, dict):
        max_dict_depth = depth
        for value in data.values():
            child_depth = max_depth(value, depth+1)
            max_dict_depth = max(max_dict_depth, child_depth)
        return max_dict_depth
    elif isinstance(data, list):
        max_list_depth = depth
        for item in data:
            child_depth = max_depth(item, depth+1)
            max_list_depth = max(max_list_depth, child_depth)
        return max_list_depth

    return depth
print(":Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ø¹Ù…Ù‚ ØªÙˆ Ø¯Ø± ØªÙˆÛŒÛŒ","\t",max_depth(data))
max_depth(data)



#Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ù‡ Ø¯Ø³Øª Ø§Ù…Ø¯Ù‡ Ø§Ù…Ø§Ø±ÛŒ Ø¹Ø¯Ø¯ÛŒ

print("Ø¯Ø§Ø¯Ù‡ Ù‡Ø§ÛŒ Ø§Ù…Ø§Ø±ÛŒ:")
print("============="*10)

from collections import defaultdict

def count_data_types(data, counter=None):
    if counter is None:
        counter = defaultdict(int)

    if isinstance(data, dict):
        counter['dict'] += 1
        for value in data.values():
            count_data_types(value, counter)

    elif isinstance(data, list):
        counter['list'] += 1
        for item in data:
            count_data_types(item, counter)

    elif isinstance(data, str):
        counter['str'] += 1

    elif isinstance(data, int):
        counter['int'] += 1

    elif isinstance(data, float):
        counter['float'] += 1

    elif data is None:
        counter['NoneType'] += 1

    elif isinstance(data, bool):
        counter['bool'] += 1

    else:
        counter[str(type(data))] += 1  # Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡

    return counter

type_counts = count_data_types(data)

print("ğŸ“Š Ø´Ù…Ø§Ø±Ø´ Ø§Ù†ÙˆØ§Ø¹ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¯Ø± ÙØ§ÛŒÙ„ JSON:")
for dtype, count in type_counts.items():
    print(f"  - {dtype}: {count}")

print("==========="*15)

import  statistics

def extract_numbers(data, numbers=None):
    if numbers is None:
        numbers = []

    if isinstance(data, dict):
        for value in data.values():
            extract_numbers(value, numbers)
    elif isinstance(data, list):
        for item in data:
            extract_numbers(item, numbers)
    elif isinstance(data, (int, float)):
        numbers.append(data)

    return numbers
# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¹Ø¯Ø¯ÛŒ
numbers = extract_numbers(data)

if numbers:
    print("ğŸ”¢ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¹Ø¯Ø¯ÛŒ:")
    print(f"  - ØªØ¹Ø¯Ø§Ø¯ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¹Ø¯Ø¯ÛŒ: {len(numbers)}")
    print(f"  - Ú©Ù…ÛŒÙ†Ù‡: {min(numbers)}")
    print(f"  - Ø¨ÛŒØ´ÛŒÙ†Ù‡: {max(numbers)}")
    print(f"  - Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†: {sum(numbers) / len(numbers):.2f}")
    print(f"  - Ù…ÛŒØ§Ù†Ù‡: {statistics.median(numbers)}")
else:
    print("ğŸ”¢ Ù‡ÛŒÚ† Ø¹Ø¯Ø¯ÛŒ Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
print("============"*15)

# Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…ØªÙ†ÛŒ
def analyze_text_data(data, text_list=None):
    if text_list is None:
        text_list = []

    if isinstance(data, dict):
        for value in data.values():
            analyze_text_data(value, text_list)
    elif isinstance(data, list):
        for item in data:
            analyze_text_data(item, text_list)
    elif isinstance(data, str):
        text_list.append(data)

    return text_list
text_data = analyze_text_data(data)  

total_strings = len(text_data)
unique_strings = len(set(text_data))

print("ğŸ”¤ ØªØ­Ù„ÛŒÙ„ Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§:")
print(f"  - ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§: {total_strings}")
print(f"  - ØªØ¹Ø¯Ø§Ø¯ Ù…Ù‚Ø§Ø¯ÛŒØ± ÛŒÚ©ØªØ§ÛŒ Ù…ØªÙ†ÛŒ: {unique_strings}")

print("============="*15)

from collections import defaultdict

def count_keys(data, counter=None):
    if counter is None:
        counter = defaultdict(int)

    if isinstance(data, dict):
        for key, value in data.items():
            counter[key] += 1
            count_keys(value, counter)
    elif isinstance(data, list):
        for item in data:
            count_keys(item, counter)

    return counter
keys_counter = count_keys(data)

# Ù†Ù…Ø§ÛŒØ´ Ù‡Ù…Ù‡ Ú©Ù„ÛŒØ¯Ù‡Ø§
print("ğŸ”‘ Ù„ÛŒØ³Øª ØªÙ…Ø§Ù… Ú©Ù„ÛŒØ¯Ù‡Ø§:")
for key, count in keys_counter.items():
    print(f"- {key}: {count} Ø¨Ø§Ø±")

# Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ú©Ù„ÛŒØ¯ ØªÚ©Ø±Ø§Ø±ÛŒ
if keys_counter:
    max_key = max(keys_counter.items(), key=lambda x: x[1])
    print(f"\nğŸ† Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ú©Ù„ÛŒØ¯ ØªÚ©Ø±Ø§Ø±Ø´ÙˆÙ†Ø¯Ù‡: Â«{max_key[0]}Â» Ø¨Ø§ {max_key[1]} Ø¨Ø§Ø± ØªÚ©Ø±Ø§Ø±")
else:
    print("Ù‡ÛŒÚ† Ú©Ù„ÛŒØ¯ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")

